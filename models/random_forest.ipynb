{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme(style=\"darkgrid\", palette=\"pastel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rl_kpis = pd.read_csv(\"/root/projects/ci_anomaly_detection/data/turkcell/final_preprocessed_df_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rl_kpis['datetime']=pd.to_datetime(rl_kpis['datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>site_id</th>\n",
       "      <th>mlid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>RL_;ABDV</td>\n",
       "      <td>A0BE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>RL_;ABDV</td>\n",
       "      <td>A0BI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>RL_;ABDV</td>\n",
       "      <td>A5AB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>RL_;ABDV</td>\n",
       "      <td>A8CQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>RL_;ABDV</td>\n",
       "      <td>A8DQ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    datetime   site_id  mlid\n",
       "0 2018-12-31  RL_;ABDV  A0BE\n",
       "1 2018-12-31  RL_;ABDV  A0BI\n",
       "2 2018-12-31  RL_;ABDV  A5AB\n",
       "3 2018-12-31  RL_;ABDV  A8CQ\n",
       "4 2018-12-31  RL_;ABDV  A8DQ"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels = rl_kpis[[\"datetime\", \"site_id\", \"mlid\"]]\n",
    "df_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11418/3134115453.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_labels[f\"T+{i+1}\"] = df_labels[\"datetime\"] + pd.DateOffset(days=i+1)\n",
      "/tmp/ipykernel_11418/3134115453.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_labels[f\"T+{i+1}\"] = df_labels[\"datetime\"] + pd.DateOffset(days=i+1)\n",
      "/tmp/ipykernel_11418/3134115453.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_labels[f\"T+{i+1}\"] = df_labels[\"datetime\"] + pd.DateOffset(days=i+1)\n",
      "/tmp/ipykernel_11418/3134115453.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_labels[f\"T+{i+1}\"] = df_labels[\"datetime\"] + pd.DateOffset(days=i+1)\n",
      "/tmp/ipykernel_11418/3134115453.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_labels[f\"T+{i+1}\"] = df_labels[\"datetime\"] + pd.DateOffset(days=i+1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>site_id</th>\n",
       "      <th>mlid</th>\n",
       "      <th>T+1</th>\n",
       "      <th>T+2</th>\n",
       "      <th>T+3</th>\n",
       "      <th>T+4</th>\n",
       "      <th>T+5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>RL_;ABDV</td>\n",
       "      <td>A0BE</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>2019-01-04</td>\n",
       "      <td>2019-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>RL_;ABDV</td>\n",
       "      <td>A0BI</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>2019-01-04</td>\n",
       "      <td>2019-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>RL_;ABDV</td>\n",
       "      <td>A5AB</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>2019-01-04</td>\n",
       "      <td>2019-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>RL_;ABDV</td>\n",
       "      <td>A8CQ</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>2019-01-04</td>\n",
       "      <td>2019-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>RL_;ABDV</td>\n",
       "      <td>A8DQ</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>2019-01-04</td>\n",
       "      <td>2019-01-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    datetime   site_id  mlid        T+1        T+2        T+3        T+4  \\\n",
       "0 2018-12-31  RL_;ABDV  A0BE 2019-01-01 2019-01-02 2019-01-03 2019-01-04   \n",
       "1 2018-12-31  RL_;ABDV  A0BI 2019-01-01 2019-01-02 2019-01-03 2019-01-04   \n",
       "2 2018-12-31  RL_;ABDV  A5AB 2019-01-01 2019-01-02 2019-01-03 2019-01-04   \n",
       "3 2018-12-31  RL_;ABDV  A8CQ 2019-01-01 2019-01-02 2019-01-03 2019-01-04   \n",
       "4 2018-12-31  RL_;ABDV  A8DQ 2019-01-01 2019-01-02 2019-01-03 2019-01-04   \n",
       "\n",
       "         T+5  \n",
       "0 2019-01-05  \n",
       "1 2019-01-05  \n",
       "2 2019-01-05  \n",
       "3 2019-01-05  \n",
       "4 2019-01-05  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_interval = 5\n",
    "\n",
    "for i in range(prediction_interval):\n",
    "  df_labels[f\"T+{i+1}\"] = df_labels[\"datetime\"] + pd.DateOffset(days=i+1)\n",
    "df_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>site_id</th>\n",
       "      <th>mlid</th>\n",
       "      <th>T+1</th>\n",
       "      <th>T+2</th>\n",
       "      <th>T+3</th>\n",
       "      <th>T+4</th>\n",
       "      <th>T+5</th>\n",
       "      <th>T+1_rlf</th>\n",
       "      <th>T+2_rlf</th>\n",
       "      <th>T+3_rlf</th>\n",
       "      <th>T+4_rlf</th>\n",
       "      <th>T+5_rlf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>RL_;ABDV</td>\n",
       "      <td>A0BE</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>2019-01-04</td>\n",
       "      <td>2019-01-05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>RL_;ABDV</td>\n",
       "      <td>A0BI</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>2019-01-04</td>\n",
       "      <td>2019-01-05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>RL_;ABDV</td>\n",
       "      <td>A5AB</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>2019-01-04</td>\n",
       "      <td>2019-01-05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>RL_;ABDV</td>\n",
       "      <td>A8CQ</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>2019-01-04</td>\n",
       "      <td>2019-01-05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>RL_;ABDV</td>\n",
       "      <td>A8DQ</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>2019-01-04</td>\n",
       "      <td>2019-01-05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    datetime   site_id  mlid        T+1        T+2        T+3        T+4  \\\n",
       "0 2018-12-31  RL_;ABDV  A0BE 2019-01-01 2019-01-02 2019-01-03 2019-01-04   \n",
       "1 2018-12-31  RL_;ABDV  A0BI 2019-01-01 2019-01-02 2019-01-03 2019-01-04   \n",
       "2 2018-12-31  RL_;ABDV  A5AB 2019-01-01 2019-01-02 2019-01-03 2019-01-04   \n",
       "3 2018-12-31  RL_;ABDV  A8CQ 2019-01-01 2019-01-02 2019-01-03 2019-01-04   \n",
       "4 2018-12-31  RL_;ABDV  A8DQ 2019-01-01 2019-01-02 2019-01-03 2019-01-04   \n",
       "\n",
       "         T+5  T+1_rlf  T+2_rlf  T+3_rlf  T+4_rlf  T+5_rlf  \n",
       "0 2019-01-05      0.0      0.0      0.0      0.0      0.0  \n",
       "1 2019-01-05      0.0      0.0      0.0      0.0      0.0  \n",
       "2 2019-01-05      0.0      0.0      0.0      0.0      0.0  \n",
       "3 2019-01-05      0.0      0.0      0.0      0.0      0.0  \n",
       "4 2019-01-05      0.0      0.0      0.0      0.0      0.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rl_kpis_view = rl_kpis[[\"datetime\", \"site_id\", \"mlid\", \"rlf\"]]\n",
    "for i in range(prediction_interval):\n",
    "  target_day_column_name = f\"T+{i+1}\"\n",
    "\n",
    "  df_labels = df_labels.merge(rl_kpis_view, \n",
    "                  how = \"left\", \n",
    "                  left_on = (\"site_id\", \"mlid\", target_day_column_name),\n",
    "                  right_on = (\"site_id\", \"mlid\", \"datetime\"),\n",
    "                  suffixes = (\"\", \"_y\")\n",
    "  )\n",
    "  df_labels.rename(columns={\"rlf\": f\"{target_day_column_name}_rlf\"}, inplace=True)\n",
    "df_labels.drop(columns=[\"datetime_y\"], inplace=True)\n",
    "df_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_labels.shape: (1992986, 5)\n",
      "df_labels 1-day rlf sum: 1204.0\n",
      "df_labels 5-day rlf sum: 5159\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>site_id</th>\n",
       "      <th>mlid</th>\n",
       "      <th>1-day-predict</th>\n",
       "      <th>5-day-predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>RL_;ABDV</td>\n",
       "      <td>A0BE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>RL_;ABDV</td>\n",
       "      <td>A0BI</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>RL_;ABDV</td>\n",
       "      <td>A5AB</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>RL_;ABDV</td>\n",
       "      <td>A8CQ</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>RL_;ABDV</td>\n",
       "      <td>A8DQ</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    datetime   site_id  mlid  1-day-predict  5-day-predict\n",
       "0 2018-12-31  RL_;ABDV  A0BE            0.0          False\n",
       "1 2018-12-31  RL_;ABDV  A0BI            0.0          False\n",
       "2 2018-12-31  RL_;ABDV  A5AB            0.0          False\n",
       "3 2018-12-31  RL_;ABDV  A8CQ            0.0          False\n",
       "4 2018-12-31  RL_;ABDV  A8DQ            0.0          False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1 day predict is equal to T+1 rlf\n",
    "df_labels[\"1-day-predict\"] = df_labels[\"T+1_rlf\"]\n",
    "\n",
    "# Interval predict (5-day predict) is based on T+1, T+2, T+3, T+4 and T+5\n",
    "following_days_rlf_columns = [f\"T+{i+1}_rlf\" for i in range(prediction_interval)]\n",
    "\n",
    "df_labels[\"5-day-predict\"] = df_labels[following_days_rlf_columns].any(axis=1)\n",
    "df_labels = df_labels[[\"datetime\", \"site_id\", \"mlid\", \"1-day-predict\", \"5-day-predict\"]]\n",
    "\n",
    "print(f\"df_labels.shape: {df_labels.shape}\")\n",
    "print(f\"df_labels 1-day rlf sum: {df_labels['1-day-predict'].sum()}\")\n",
    "print(f\"df_labels 5-day rlf sum: {df_labels['5-day-predict'].sum()}\")\n",
    "df_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>datetime</th>\n",
       "      <th>tip</th>\n",
       "      <th>mlid</th>\n",
       "      <th>mw_connection_no</th>\n",
       "      <th>site_id</th>\n",
       "      <th>card_type</th>\n",
       "      <th>adaptive_modulation</th>\n",
       "      <th>freq_band</th>\n",
       "      <th>severaly_error_second</th>\n",
       "      <th>...</th>\n",
       "      <th>humidity_mean_3</th>\n",
       "      <th>precipitation_mean_3</th>\n",
       "      <th>precipitation_coeff_mean_3</th>\n",
       "      <th>bbe_3</th>\n",
       "      <th>error_second_3</th>\n",
       "      <th>severaly_error_second_3</th>\n",
       "      <th>error_second_3.1</th>\n",
       "      <th>unavail_second_3</th>\n",
       "      <th>1-day-predict</th>\n",
       "      <th>5-day-predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENK</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>FAR</td>\n",
       "      <td>A0BE</td>\n",
       "      <td>1,349,988</td>\n",
       "      <td>RL_;ABDV</td>\n",
       "      <td>cardtype1</td>\n",
       "      <td>Enable</td>\n",
       "      <td>f3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENK</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>FAR</td>\n",
       "      <td>A0BI</td>\n",
       "      <td>1,349,988</td>\n",
       "      <td>RL_;ABDV</td>\n",
       "      <td>cardtype1</td>\n",
       "      <td>Enable</td>\n",
       "      <td>f3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENK</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>FAR</td>\n",
       "      <td>A5AB</td>\n",
       "      <td>1,344,018</td>\n",
       "      <td>RL_;ABDV</td>\n",
       "      <td>cardtype4</td>\n",
       "      <td>Enable</td>\n",
       "      <td>f3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NEC</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>FAR</td>\n",
       "      <td>A8CQ</td>\n",
       "      <td>1,351,204</td>\n",
       "      <td>RL_;ABDV</td>\n",
       "      <td>cardtype5</td>\n",
       "      <td>Enable</td>\n",
       "      <td>f2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NEC</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>FAR</td>\n",
       "      <td>A8DQ</td>\n",
       "      <td>1,351,204</td>\n",
       "      <td>RL_;ABDV</td>\n",
       "      <td>cardtype5</td>\n",
       "      <td>Enable</td>\n",
       "      <td>f2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 89 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  type   datetime  tip  mlid mw_connection_no   site_id  card_type  \\\n",
       "0  ENK 2018-12-31  FAR  A0BE        1,349,988  RL_;ABDV  cardtype1   \n",
       "1  ENK 2018-12-31  FAR  A0BI        1,349,988  RL_;ABDV  cardtype1   \n",
       "2  ENK 2018-12-31  FAR  A5AB        1,344,018  RL_;ABDV  cardtype4   \n",
       "3  NEC 2018-12-31  FAR  A8CQ        1,351,204  RL_;ABDV  cardtype5   \n",
       "4  NEC 2018-12-31  FAR  A8DQ        1,351,204  RL_;ABDV  cardtype5   \n",
       "\n",
       "  adaptive_modulation freq_band  severaly_error_second  ...  humidity_mean_3  \\\n",
       "0              Enable        f3                    0.0  ...              NaN   \n",
       "1              Enable        f3                    0.0  ...              NaN   \n",
       "2              Enable        f3                    0.0  ...              NaN   \n",
       "3              Enable        f2                    0.0  ...              NaN   \n",
       "4              Enable        f2                    0.0  ...              NaN   \n",
       "\n",
       "   precipitation_mean_3  precipitation_coeff_mean_3  bbe_3  error_second_3  \\\n",
       "0                   NaN                         NaN    NaN             NaN   \n",
       "1                   NaN                         NaN    NaN             NaN   \n",
       "2                   NaN                         NaN    NaN             NaN   \n",
       "3                   NaN                         NaN    NaN             NaN   \n",
       "4                   NaN                         NaN    NaN             NaN   \n",
       "\n",
       "   severaly_error_second_3 error_second_3.1  unavail_second_3  1-day-predict  \\\n",
       "0                      NaN              NaN               NaN            0.0   \n",
       "1                      NaN              NaN               NaN            0.0   \n",
       "2                      NaN              NaN               NaN            0.0   \n",
       "3                      NaN              NaN               NaN            0.0   \n",
       "4                      NaN              NaN               NaN            0.0   \n",
       "\n",
       "   5-day-predict  \n",
       "0          False  \n",
       "1          False  \n",
       "2          False  \n",
       "3          False  \n",
       "4          False  \n",
       "\n",
       "[5 rows x 89 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now join labels with rl-kpis\n",
    "rl_kpis_with_labels = rl_kpis.merge(df_labels, \n",
    "                                    how=\"left\", \n",
    "                                    on=[\"datetime\", \"site_id\", \"mlid\"])\n",
    "rl_kpis_with_labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['type',\n",
       " 'tip',\n",
       " 'mlid',\n",
       " 'mw_connection_no',\n",
       " 'site_id',\n",
       " 'card_type',\n",
       " 'adaptive_modulation',\n",
       " 'freq_band',\n",
       " 'modulation']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(rl_kpis.select_dtypes(include=['object']).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features =  [\"card_type\", \"freq_band\",]\n",
    "numerical_features = list(set(rl_kpis.columns) - set(categorical_features) - set(['type','tip','mlid','mw_connection_no','site_id','adaptive_modulation','modulation','datetime']))\n",
    "\n",
    "features = categorical_features + numerical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rlf count:  5159\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(15477, 89)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simple undersampling\n",
    "np.random.seed(1234)\n",
    "\n",
    "cond_rlf = rl_kpis_with_labels[\"5-day-predict\"]\n",
    "rlf_count = cond_rlf.sum()\n",
    "print(\"rlf count: \", rlf_count)\n",
    "\n",
    "# Get sample index from non rlf columns with 1:3 ratio\n",
    "sampled_non_rlf_indicies = np.random.choice(rl_kpis_with_labels[~cond_rlf].index, size=rlf_count * 2)\n",
    "rlf_indicies = np.array(rl_kpis_with_labels[cond_rlf].index)\n",
    "\n",
    "sampled_data_indicies = list(sampled_non_rlf_indicies) + list(rlf_indicies)\n",
    "sampled_data = rl_kpis_with_labels.loc[sampled_data_indicies]\n",
    "sampled_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train.shape: (12381, 89) | df_test.shape: (3096, 89)\n"
     ]
    }
   ],
   "source": [
    "df_train, df_test = train_test_split(sampled_data, test_size=0.2)\n",
    "print(f\"df_train.shape: {df_train.shape} | df_test.shape: {df_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Создаётся новый OneHotEncoder...\n",
      "OneHotEncoder создан и обучен:\n",
      "**************************************************\n",
      "Названия признаков: ['card_type_cardtype1' 'card_type_cardtype10' 'card_type_cardtype11'\n",
      " 'card_type_cardtype2' 'card_type_cardtype4' 'card_type_cardtype5'\n",
      " 'card_type_cardtype6' 'freq_band_f0' 'freq_band_f1' 'freq_band_f2'\n",
      " 'freq_band_f3' 'freq_band_f4' 'freq_band_f5']\n",
      "**************************************************\n",
      "Категории: [array(['cardtype1', 'cardtype10', 'cardtype11', 'cardtype2', 'cardtype4',\n",
      "       'cardtype5', 'cardtype6'], dtype=object), array(['f0', 'f1', 'f2', 'f3', 'f4', 'f5'], dtype=object)]\n"
     ]
    }
   ],
   "source": [
    "# Convert categorical columns to one hot vector\n",
    "# Merge them with numerical columns\n",
    "# Return X data, column names, and encoder for future usage\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "def preprocessing(df, numerical_columns=[], categorical_columns=[], one_hot_encoder=None):\n",
    "    df = df.dropna()\n",
    "\n",
    "    # Проверка наличия столбцов в DataFrame\n",
    "    for col in numerical_columns + categorical_columns:\n",
    "        if col not in df.columns:\n",
    "            raise ValueError(f\"Столбец '{col}' отсутствует в DataFrame!\")\n",
    "\n",
    "    if one_hot_encoder is None:\n",
    "        one_hot_encoder = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    "        one_hot_encoder.fit(df[categorical_columns])\n",
    "        print(\"*\" * 50)\n",
    "        print(\"Названия признаков:\", one_hot_encoder.get_feature_names_out(categorical_columns))\n",
    "        print(\"*\" * 50)\n",
    "        print(\"Категории:\", one_hot_encoder.categories_)\n",
    "\n",
    "    # Преобразуем числовые столбцы в массив NumPy\n",
    "    arr_numerical = df[numerical_columns].to_numpy()\n",
    "\n",
    "    try:\n",
    "        arr_categorical = one_hot_encoder.transform(df[categorical_columns])\n",
    "    except ValueError as e:\n",
    "        raise ValueError(f\"Ошибка при трансформации категориальных данных: {e}\")\n",
    "\n",
    "    if arr_numerical.shape[0] != arr_categorical.shape[0]:\n",
    "        raise ValueError(\"Количество строк в числовых и категориальных данных не совпадает!\")\n",
    "\n",
    "    arr_x = np.concatenate((arr_numerical, arr_categorical), axis=1)\n",
    "\n",
    "    feature_names = numerical_columns + one_hot_encoder.get_feature_names_out(categorical_columns).tolist()\n",
    "\n",
    "    return df.copy(), arr_x, feature_names, one_hot_encoder\n",
    "\n",
    "\n",
    "df_train_dropped, train_x, feature_names, one_hot_encoder = preprocessing(\n",
    "    df_train,\n",
    "    numerical_columns=numerical_features,\n",
    "    categorical_columns=categorical_features\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_1_day_pred = RandomForestClassifier(class_weight='balanced')\n",
    "\n",
    "clf_5_day_pred = RandomForestClassifier(class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_x is prepared at preprocessing step\n",
    "train_y_1_day_pred = df_train_dropped[\"1-day-predict\"].astype('int').to_numpy()\n",
    "train_y_5_day_pred = df_train_dropped[\"5-day-predict\"].astype('int').to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = clf_1_day_pred.fit(train_x, train_y_1_day_pred)\n",
    "_= clf_5_day_pred.fit(train_x, train_y_5_day_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(166, 832)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Preprocess test data\n",
    "df_test_dropepd, test_x, _, _ = preprocessing(df_test, numerical_columns=numerical_features, \n",
    "                             categorical_columns=categorical_features, \n",
    "                             one_hot_encoder=one_hot_encoder)\n",
    "test_y_1_day_pred = df_test_dropepd[\"1-day-predict\"].astype('int').to_numpy()\n",
    "test_y_5_day_pred = df_test_dropepd[\"5-day-predict\"].astype('int').to_numpy()\n",
    "\n",
    "pred_1_day = clf_1_day_pred.predict(test_x)\n",
    "pred_5_day = clf_5_day_pred.predict(test_x)\n",
    "pred_1_day.sum(), pred_5_day.sum()\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********** SCORE for 1-DAY predict\n",
      "precision : 0.5592\n",
      "recall    : 0.8253\n",
      "f-score   : 0.6667\n",
      "\n",
      "*********** SCORE for 5-DAY predict ***********\n",
      "precision : 0.6979\n",
      "recall    : 0.8329\n",
      "f-score   : 0.7595\n"
     ]
    }
   ],
   "source": [
    "precision, recall, fscore, _ = precision_recall_fscore_support(pred_1_day, \n",
    "                                                               test_y_1_day_pred, \n",
    "                                                               average=\"binary\", # \n",
    "                                                               labels=[0, 1], # labels\n",
    "                                                               beta=1) # f1 score\n",
    "\n",
    "print(\"*********** SCORE for 1-DAY predict\")\n",
    "print(f\"precision : {precision:.4f}\")\n",
    "print(f\"recall    : {recall:.4f}\")\n",
    "print(f\"f-score   : {fscore:.4f}\")\n",
    "\n",
    "\n",
    "precision, recall, fscore, _ = precision_recall_fscore_support(pred_5_day,        # y'\n",
    "                                                               test_y_5_day_pred, # y\n",
    "                                                               average=\"binary\",  # focus only True class\n",
    "                                                               labels=[0, 1],     # labels\n",
    "                                                               beta=1)            # f1 score\n",
    "print()\n",
    "print(\"*********** SCORE for 5-DAY predict ***********\")\n",
    "print(f\"precision : {precision:.4f}\")\n",
    "print(f\"recall    : {recall:.4f}\")\n",
    "print(f\"f-score   : {fscore:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
